{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import coalesce\n",
    "from torch_geometric.data import (InMemoryDataset, download_url, extract_zip,\n",
    "                                  Data)\n",
    "\n",
    "import pandas as pd\n",
    "try:\n",
    "    import rdkit\n",
    "    from rdkit import Chem\n",
    "    from rdkit import rdBase\n",
    "    from rdkit.Chem.rdchem import HybridizationType\n",
    "    from rdkit import RDConfig\n",
    "    from rdkit.Chem import ChemicalFeatures\n",
    "    from rdkit.Chem.rdchem import BondType as BT\n",
    "    rdBase.DisableLog('rdApp.error')\n",
    "except ImportError:\n",
    "    rdkit = None\n",
    "\n",
    "\n",
    "\n",
    "class QM9(InMemoryDataset):\n",
    "    r\"\"\"The QM9 dataset from the `\"MoleculeNet: A Benchmark for Molecular\n",
    "    Machine Learning\" <https://arxiv.org/abs/1703.00564>`_ paper, consisting of\n",
    "    about 130,000 molecules with 16 regression targets.\n",
    "   \n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "        pre_filter (callable, optional): A function that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a boolean\n",
    "            value, indicating whether the data object should be included in the\n",
    "            final dataset. (default: :obj:`None`)\n",
    "    \"\"\"  # noqa: E501\n",
    "\n",
    "    raw_url = ('https://s3-us-west-1.amazonaws.com/deepchem.io/datasets/'\n",
    "               'molnet_publish/qm9.zip')\n",
    "    raw_url2 = 'https://ndownloader.figshare.com/files/3195404'\n",
    "    processed_url = 'http://www.roemisch-drei.de/qm9.zip'\n",
    "\n",
    "    if rdkit is not None:\n",
    "        types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4, 'Cl':5,'Br':6, 'I':7,'P':8, 'S':9}\n",
    "        #add more Elements, numbering without specific rational\n",
    "        bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None,\n",
    "                 pre_filter=None):\n",
    "        super(QM9, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])# data is from processed\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        if rdkit is None:\n",
    "            return 'qm9_preHOMO.pt'\n",
    "        else:\n",
    "            return ['gdb9.sdf', 'qm_homo.csv', 'uncharacterized.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'qm9_preHOMO.pt'\n",
    "\n",
    "    \"\"\"def download(self):\n",
    "        if rdkit is None:\n",
    "            file_path = download_url(self.processed_url, self.raw_dir)\n",
    "            extract_zip(file_path, self.raw_dir)\n",
    "            os.unlink(file_path)\n",
    "        else:\n",
    "            file_path = download_url(self.raw_url, self.raw_dir)\n",
    "            extract_zip(file_path, self.raw_dir)\n",
    "            os.unlink(file_path)\n",
    "\n",
    "            file_path = download_url(self.raw_url2, self.raw_dir)\n",
    "            os.rename(\n",
    "                osp.join(self.raw_dir, '3195404'),\n",
    "                osp.join(self.raw_dir, 'uncharacterized.txt'))\n",
    "\"\"\"\n",
    "    def process(self):\n",
    "        if rdkit is None:\n",
    "            print('Using a pre-processed version of the dataset. Please '\n",
    "                  'install `rdkit` to alternatively process the raw data.')\n",
    "\n",
    "            self.data, self.slices = torch.load(self.raw_paths[0])\n",
    "            data_list = [self.get(i) for i in range(len(self))]\n",
    "\n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "            data, slices = self.collate(data_list)\n",
    "            torch.save((data, slices), self.processed_paths[0])\n",
    "            return\n",
    "\n",
    "        with open(self.raw_paths[1], 'r') as f:#csv seems to be read\n",
    "            target = f.read().split('\\n')[:-1]\n",
    "            target = [float(x) for x in target]#20 is the number of columns in the csv\n",
    "            target = torch.tensor(target, dtype=torch.float)\n",
    "            target = torch.cat([target[:], target[:]], dim=-1) # First 3 col. of the csv are ignored @orig\n",
    "            target = target.view(target.size(0), -1)\n",
    "\n",
    "\n",
    "        \"\"\"with open(self.raw_paths[2], 'r') as f: # read me is read\n",
    "            skip = [int(x.split()[0]) for x in f.read().split('\\n')[9:-2]]\n",
    "        assert len(skip) == 3054\n",
    "\"\"\"\n",
    "        suppl = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False)#sdf is read\n",
    "        fdef_name = osp.join(RDConfig.RDDataDir, 'BaseFeatures.fdef') #whats that\n",
    "        factory = ChemicalFeatures.BuildFeatureFactory(fdef_name)\n",
    "\n",
    "        data_list = []\n",
    "        for i, mol in enumerate(suppl):\n",
    "            if mol is None:\n",
    "                continue\n",
    "            \"\"\"if i in skip:#something from the readme file is skipped???? looksa like it is capturing text\n",
    "                continue\"\"\"\n",
    "\n",
    "            text = suppl.GetItemText(i)#\n",
    "            N = mol.GetNumAtoms()\n",
    "                 \n",
    "            pos = text.split('\\n')[4:4 + N]\n",
    "            pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
    "            pos = torch.tensor(pos, dtype=torch.float)\n",
    "\n",
    "            type_idx = []\n",
    "            atomic_number = []\n",
    "            acceptor = []\n",
    "            donor = []\n",
    "            aromatic = []\n",
    "            sp = []\n",
    "            sp2 = []\n",
    "            sp3 = []\n",
    "            num_hs = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                type_idx.append(self.types[atom.GetSymbol()])\n",
    "                atomic_number.append(atom.GetAtomicNum())\n",
    "                donor.append(0)\n",
    "                acceptor.append(0)\n",
    "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
    "                hybridization = atom.GetHybridization()\n",
    "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
    "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
    "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
    "                num_hs.append(atom.GetTotalNumHs(includeNeighbors=True))\n",
    "\n",
    "            feats = factory.GetFeaturesForMol(mol)\n",
    "            for j in range(0, len(feats)):\n",
    "                if feats[j].GetFamily() == 'Donor':\n",
    "                    node_list = feats[j].GetAtomIds()\n",
    "                    for k in node_list:\n",
    "                        donor[k] = 1\n",
    "                elif feats[j].GetFamily() == 'Acceptor':\n",
    "                    node_list = feats[j].GetAtomIds()\n",
    "                    for k in node_list:\n",
    "                        acceptor[k] = 1\n",
    "\n",
    "            x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(self.types))\n",
    "            x2 = torch.tensor([\n",
    "                atomic_number, acceptor, donor, aromatic, sp, sp2, sp3, num_hs\n",
    "            ], dtype=torch.float).t().contiguous()\n",
    "            x = torch.cat([x1.to(torch.float), x2], dim=-1)\n",
    "\n",
    "            row, col, bond_idx = [], [], []\n",
    "            for bond in mol.GetBonds():\n",
    "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "                row += [start, end]\n",
    "                col += [end, start]\n",
    "                bond_idx += 2 * [self.bonds[bond.GetBondType()]]\n",
    "\n",
    "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "            edge_attr = F.one_hot(\n",
    "                torch.tensor(bond_idx),\n",
    "                num_classes=len(self.bonds)).to(torch.float)\n",
    "            edge_index, edge_attr = coalesce(edge_index, edge_attr, N, N)\n",
    "\n",
    "            y = target[i].unsqueeze(0) # gets safed as 1D list in Tensor insetad of just float\n",
    "            \n",
    "            name = mol.GetProp('_Name')\n",
    "\n",
    "            data = Data(x=x, pos=pos, edge_index=edge_index,\n",
    "                        edge_attr=edge_attr, y=y, name=name)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            data_list.append(data)\n",
    "        \n",
    "        torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "\n",
    "class MyTransform(object):\n",
    "    def __call__(self, data):\n",
    "        # Specify target.\n",
    "        data.y = data.y[:, target]\n",
    "        return data\n",
    "\n",
    "\n",
    "class Complete(object):\n",
    "    def __call__(self, data):\n",
    "        device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df=pd.read_csv(\"datasets/raw/df_final_dG.txt\")\n",
    "len(y_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra libs\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "#sys.path.append('geometric')\n",
    "import torch_geometric.transforms as T\n",
    "#from torch_geometric.datasets import QM9\n",
    "import data_reader\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "\n",
    "target = 0\n",
    "dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets\"\n",
    "ds = QM9(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0., 35.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QM9(132480)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../pre_homo\"\n",
    "#dataset=QM9(path)\n",
    "transform = T.Compose([MyTransform(), Complete(), T.Distance(norm=False)])\n",
    "dataset = QM9(path, transform=transform).shuffle()\n",
    "dataset# if processing data exists the raw data wont be accessed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[306, 5], edge_index=[2, 306], name=[1], pos=[18, 3], x=[18, 18], y=[1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QM9(132480)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    print(x)\n",
    "    break\n",
    "dataset\n",
    "#len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2700e-02,  1.0858e+00,  8.0000e-03],\n",
       "        [ 2.2000e-03, -6.0000e-03,  2.0000e-03],\n",
       "        [ 1.0117e+00,  1.4638e+00,  3.0000e-04],\n",
       "        ...,\n",
       "        [ 2.5159e+00, -1.1518e+00,  5.2740e-01],\n",
       "        [ 1.3700e-02,  1.1994e+00, -1.6802e+00],\n",
       "        [ 1.2607e+00, -1.2468e+00, -1.9068e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3877],\n",
       "        [-0.2570],\n",
       "        [-0.2928],\n",
       "        ...,\n",
       "        [-0.2233],\n",
       "        [-0.2122],\n",
       "        [-0.2316]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize targets to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "mean, std = mean[:, target].item(), std[:, target].item()\n",
    "mean,std =float(mean),float(std)\n",
    "\n",
    "# Split datasets.\n",
    "len_dt=len(dataset)\n",
    "tr_dt=round(len_dt*0.8)\n",
    "eval_dt=round(len_dt*0.1)\n",
    "test_dataset = dataset[(tr_dt+eval_dt):]\n",
    "val_dataset = dataset[tr_dt:(tr_dt+eval_dt)]\n",
    "train_dataset = dataset[:tr_dt]#2760\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "debug=False\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin0 = torch.nn.Linear(dataset.num_features, dim)\n",
    "\n",
    "        nn = Sequential(Linear(5, 128), ReLU(), Linear(128, dim * dim))\n",
    "        self.conv = NNConv(dim, dim, nn, aggr='mean')\n",
    "        self.gru = GRU(dim, dim)\n",
    "\n",
    "        self.set2set = Set2Set(dim, processing_steps=3)\n",
    "        self.lin1 = torch.nn.Linear(2 * dim, dim)\n",
    "        self.lin2 = torch.nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.lin0(data.x))\n",
    "        h = out.unsqueeze(0)\n",
    "\n",
    "        for i in range(3):\n",
    "            #print(\"Data__:\",data,i,data.edge_attr.shape,\"index\",data.edge_index.shape)\n",
    "            m = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n",
    "            out, h = self.gru(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "            #if debug:\n",
    "                #break\n",
    "\n",
    "        out = self.set2set(out, data.batch)\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        return out.view(-1)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                       factor=0.7, patience=5,\n",
    "                                                       min_lr=0.00001)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #if debug:\n",
    "            #print(\"DBI:\",data.x)\n",
    "        #print(\"x\",data.x.shape,\"attr\",data.edge_attr.shape, \"edge\",data.edge_index.shape,data.y.shape)\n",
    "        #break\n",
    "        \n",
    "        loss = F.mse_loss(model(data), data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        error += (model(data) * std - data.y * std).abs().sum().item()  # MAE\n",
    "    return error / len(loader.dataset)\n",
    "\n",
    "\n",
    "best_val_error = None\n",
    "for epoch in range(1, 301):\n",
    "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    loss = train(epoch)\n",
    "    val_error = test(val_loader)\n",
    "    scheduler.step(val_error)\n",
    "\n",
    "    if best_val_error is None or val_error <= best_val_error:\n",
    "        test_error = test(test_loader)\n",
    "        best_val_error = val_error\n",
    "\n",
    "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation MAE: {:.7f}, '\n",
    "          'Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))\n",
    "PATH=\"../QM9_data/pretr_homo.pt\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
